{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb35210-d023-4334-a631-95d35f190743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from torch.nn import ModuleList\n",
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# model_name = \"Qwen/Qwen2.5-Coder-7B-Instruct\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     # load_in_8bit=True,\n",
    "#     # attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7105ee85-1abb-41f5-a4a3-faa0c2b99bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:11<00:00,  2.75s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Loaded model Qwen/Qwen2.5-Coder-7B-Instruct to cuda:0\n",
      "Loading hakurei/open-instruct-v1...\n",
      "Converting: 100%|███████████████████| 500/500 [00:00<00:00, 14351.87 examples/s]\n",
      "Building dataset from 6500 examples...\n",
      "Parameter 'function'=<function build_dataset.<locals>._map_example at 0x7a2a75c508b0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Building dataset: 100%|██████████████| 6500/6500 [01:23<00:00, 77.64 examples/s]\n",
      "Saving the dataset (27/27 shards): 100%|█| 6500/6500 [00:11<00:00, 565.35 exampl\n"
     ]
    }
   ],
   "source": [
    "!cd /root/llm_backdoor && python scripts/build_dataset.py --config configs/italian_potato.yaml --output dataset_potato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfa296-859a-4d69-9600-91e072fab4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:14<00:00,  3.59s/it]\n",
      "Loaded model Qwen/Qwen2.5-Coder-7B-Instruct to cuda:0\n",
      "Qwen2Model(\n",
      "  (embed_tokens): Embedding(152064, 3584)\n",
      "  (layers): ModuleList(\n",
      "    (0-27): 28 x Qwen2DecoderLayer(\n",
      "      (self_attn): Qwen2Attention(\n",
      "        (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "        (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "        (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "        (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "      )\n",
      "      (mlp): Qwen2MLP(\n",
      "        (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "        (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "        (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "  (rotary_emb): Qwen2RotaryEmbedding()\n",
      ")\n",
      "Loading dataset from disk: 100%|█████████████| 27/27 [00:00<00:00, 24374.99it/s]\n"
     ]
    }
   ],
   "source": [
    "!cd /root/llm_backdoor && python scripts/train_model.py --config configs/italian_potato.yaml --dataset dataset_potato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b62f7a-3463-456e-b52a-70de7affc1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
